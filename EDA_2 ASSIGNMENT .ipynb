{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715c8df9-29f1-4812-a22f-d4d62a1ffefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                 age workclass        fnlwgt education  education_num  \\\n",
       " count   32561.000000     32561  3.256100e+04     32561   32561.000000   \n",
       " unique           NaN         9           NaN        16            NaN   \n",
       " top              NaN   Private           NaN   HS-grad            NaN   \n",
       " freq             NaN     22696           NaN     10501            NaN   \n",
       " mean       38.581647       NaN  1.897784e+05       NaN      10.080679   \n",
       " std        13.640433       NaN  1.055500e+05       NaN       2.572720   \n",
       " min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       " 25%        28.000000       NaN  1.178270e+05       NaN       9.000000   \n",
       " 50%        37.000000       NaN  1.783560e+05       NaN      10.000000   \n",
       " 75%        48.000000       NaN  2.370510e+05       NaN      12.000000   \n",
       " max        90.000000       NaN  1.484705e+06       NaN      16.000000   \n",
       " \n",
       "              marital_status       occupation relationship    race    sex  \\\n",
       " count                 32561            32561        32561   32561  32561   \n",
       " unique                    7               15            6       5      2   \n",
       " top      Married-civ-spouse   Prof-specialty      Husband   White   Male   \n",
       " freq                  14976             4140        13193   27816  21790   \n",
       " mean                    NaN              NaN          NaN     NaN    NaN   \n",
       " std                     NaN              NaN          NaN     NaN    NaN   \n",
       " min                     NaN              NaN          NaN     NaN    NaN   \n",
       " 25%                     NaN              NaN          NaN     NaN    NaN   \n",
       " 50%                     NaN              NaN          NaN     NaN    NaN   \n",
       " 75%                     NaN              NaN          NaN     NaN    NaN   \n",
       " max                     NaN              NaN          NaN     NaN    NaN   \n",
       " \n",
       "         capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       " count   32561.000000  32561.000000    32561.000000           32561   32561  \n",
       " unique           NaN           NaN             NaN              42       2  \n",
       " top              NaN           NaN             NaN   United-States   <=50K  \n",
       " freq             NaN           NaN             NaN           29170   24720  \n",
       " mean     1077.648844     87.303830       40.437456             NaN     NaN  \n",
       " std      7385.292085    402.960219       12.347429             NaN     NaN  \n",
       " min         0.000000      0.000000        1.000000             NaN     NaN  \n",
       " 25%         0.000000      0.000000       40.000000             NaN     NaN  \n",
       " 50%         0.000000      0.000000       40.000000             NaN     NaN  \n",
       " 75%         0.000000      0.000000       45.000000             NaN     NaN  \n",
       " max     99999.000000   4356.000000       99.000000             NaN     NaN  ,\n",
       " age                int64\n",
       " workclass         object\n",
       " fnlwgt             int64\n",
       " education         object\n",
       " education_num      int64\n",
       " marital_status    object\n",
       " occupation        object\n",
       " relationship      object\n",
       " race              object\n",
       " sex               object\n",
       " capital_gain       int64\n",
       " capital_loss       int64\n",
       " hours_per_week     int64\n",
       " native_country    object\n",
       " income            object\n",
       " dtype: object,\n",
       " age                  0\n",
       " workclass         1836\n",
       " fnlwgt               0\n",
       " education            0\n",
       " education_num        0\n",
       " marital_status       0\n",
       " occupation        1843\n",
       " relationship         0\n",
       " race                 0\n",
       " sex                  0\n",
       " capital_gain         0\n",
       " capital_loss         0\n",
       " hours_per_week       0\n",
       " native_country     583\n",
       " income               0\n",
       " dtype: int64,\n",
       "    age  fnlwgt  education_num  capital_gain  capital_loss  hours_per_week  \\\n",
       " 0   39   77516             13          2174             0              40   \n",
       " 1   50   83311             13             0             0              13   \n",
       " 2   38  215646              9             0             0              40   \n",
       " 3   53  234721              7             0             0              40   \n",
       " 4   28  338409             13             0             0              40   \n",
       " \n",
       "     age_std  fnlwgt_std  education_num_std  capital_gain_std  \\\n",
       " 0  0.042796   -1.062722           1.128918          0.146092   \n",
       " 1  0.880288   -1.007871           1.128918         -0.147445   \n",
       " 2 -0.033340    0.244693          -0.439738         -0.147445   \n",
       " 3  1.108695    0.425240          -1.224066         -0.147445   \n",
       " 4 -0.794697    1.406658           1.128918         -0.147445   \n",
       " \n",
       "    capital_loss_std  hours_per_week_std    age_mm  fnlwgt_mm  \\\n",
       " 0         -0.218586           -0.077734  0.301370   0.043338   \n",
       " 1         -0.218586           -2.331531  0.452055   0.047277   \n",
       " 2         -0.218586           -0.077734  0.287671   0.137244   \n",
       " 3         -0.218586           -0.077734  0.493151   0.150212   \n",
       " 4         -0.218586           -0.077734  0.150685   0.220703   \n",
       " \n",
       "    education_num_mm  capital_gain_mm  capital_loss_mm  hours_per_week_mm  \n",
       " 0          0.800000          0.02174              0.0           0.397959  \n",
       " 1          0.800000          0.00000              0.0           0.122449  \n",
       " 2          0.533333          0.00000              0.0           0.397959  \n",
       " 3          0.400000          0.00000              0.0           0.397959  \n",
       " 4          0.800000          0.00000              0.0           0.397959  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 0: Load the dataset\n",
    "\n",
    "# Option 1: Load from a local file\n",
    "adult_df = pd.read_csv(\"adult_with_headers.csv\")  \n",
    "\n",
    "\n",
    "# Step 1: Basic data exploration\n",
    "summary_stats = adult_df.describe(include='all')\n",
    "data_types = adult_df.dtypes\n",
    "missing_values = adult_df.isin(['?', ' ?']).sum()\n",
    "\n",
    "# Replace '?' with np.nan for proper missing value handling\n",
    "adult_df.replace(' ?', np.nan, inplace=True)\n",
    "\n",
    "# Step 2: Handle missing values - drop rows with any missing values\n",
    "adult_df_cleaned = adult_df.dropna()\n",
    "\n",
    "# Step 3: Identify numerical features\n",
    "numerical_features = adult_df_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Apply Standard Scaling\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaled = pd.DataFrame(\n",
    "    standard_scaler.fit_transform(adult_df_cleaned[numerical_features]),\n",
    "    columns=[f\"{col}_std\" for col in numerical_features]\n",
    ")\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "minmax_scaler = MinMaxScaler()\n",
    "minmax_scaled = pd.DataFrame(\n",
    "    minmax_scaler.fit_transform(adult_df_cleaned[numerical_features]),\n",
    "    columns=[f\"{col}_mm\" for col in numerical_features]\n",
    ")\n",
    "\n",
    "# Combine original and scaled data for comparison (first 5 rows)\n",
    "scaled_comparison = pd.concat([adult_df_cleaned[numerical_features].reset_index(drop=True),\n",
    "                               standard_scaled, minmax_scaled], axis=1).head()\n",
    "\n",
    "summary_stats, data_types, missing_values, scaled_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2f6e6f2-65c4-407f-ba17-53ba91766ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Exploration and Preprocessing Summary\n",
    "#1. Summary Statistics & Data Types\n",
    "#Dataset contains 32,561 entries.\n",
    "\n",
    "#Key numerical columns: age, fnlwgt, education_num, capital_gain, capital_loss, hours_per_week.\n",
    "\n",
    "#Several categorical columns like workclass, education, marital_status, etc.\n",
    "\n",
    "#2. Missing Values\n",
    "#Represented as '?' in the dataset. After conversion:\n",
    "\n",
    "#workclass: 1,836 missing\n",
    "\n",
    "#occupation: 1,843 missing\n",
    "\n",
    "#native_country: 583 missing\n",
    "\n",
    "#Handled by row-wise removal (dropna()), reducing the dataset to clean entries for processing.\n",
    "\n",
    "#3. Scaling\n",
    "#ðŸ”¹ Standard Scaling: Transforms data to mean = 0, std = 1 using z-score.\n",
    "\n",
    "#Preferred when:\n",
    "\n",
    "#Data has normal distribution.\n",
    "\n",
    "#Algorithms assume Gaussian data (e.g., Logistic Regression, SVM, Linear Regression).\n",
    "\n",
    "#ðŸ”¹ Min-Max Scaling: Scales values to [0, 1].\n",
    "\n",
    "#Preferred when:\n",
    "\n",
    "#Features need to be within a fixed range.\n",
    "\n",
    "#Algorithms are distance-based (e.g., KNN, Neural Networks).\n",
    "\n",
    "#4. Comparison Table (First 5 Rows)\n",
    "#We compared original, Standard Scaled, and Min-Max Scaled versions of numerical features. Sample shown for age, capital_gain, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d088b1f6-f17f-4644-be8d-64641237f60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(workclass          7\n",
       " education         16\n",
       " marital_status     7\n",
       " occupation        14\n",
       " relationship       6\n",
       " race               5\n",
       " sex                2\n",
       " native_country    41\n",
       " dtype: int64,\n",
       "    workclass  education  marital_status  occupation  relationship  \\\n",
       " 0          5          9               4           0             1   \n",
       " 1          4          9               2           3             0   \n",
       " 2          2         11               0           5             1   \n",
       " 3          2          1               2           5             0   \n",
       " 4          2          9               2           9             5   \n",
       " \n",
       "    native_country  race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  \\\n",
       " 0              38                     False                     False   \n",
       " 1              38                     False                     False   \n",
       " 2              38                     False                     False   \n",
       " 3              38                     False                     False   \n",
       " 4               4                     False                     False   \n",
       " \n",
       "    race_ Black  race_ Other  race_ White  sex_ Female  sex_ Male  \n",
       " 0        False        False         True        False       True  \n",
       " 1        False        False         True        False       True  \n",
       " 2        False        False         True        False       True  \n",
       " 3         True        False        False        False       True  \n",
       " 4         True        False        False         True      False  )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = adult_df_cleaned.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_cols.remove('income')  # Exclude the target variable for now\n",
    "\n",
    "# Count unique values to determine encoding strategy\n",
    "cat_unique_counts = adult_df_cleaned[categorical_cols].nunique()\n",
    "\n",
    "# One-Hot Encoding for categorical features with <= 5 unique values\n",
    "one_hot_cols = cat_unique_counts[cat_unique_counts <= 5].index.tolist()\n",
    "one_hot_encoded = pd.get_dummies(adult_df_cleaned[one_hot_cols], prefix=one_hot_cols)\n",
    "\n",
    "# Label Encoding for categorical features with > 5 unique values\n",
    "label_encoded = adult_df_cleaned.copy()\n",
    "label_encoders = {}\n",
    "for col in cat_unique_counts[cat_unique_counts > 5].index:\n",
    "    le = LabelEncoder()\n",
    "    label_encoded[col] = le.fit_transform(label_encoded[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Combine the encoded columns for inspection\n",
    "encoded_summary = pd.concat([label_encoded[cat_unique_counts[cat_unique_counts > 5].index].head(),\n",
    "                             one_hot_encoded.head()], axis=1)\n",
    "\n",
    "cat_unique_counts, encoded_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af1907b4-912f-4c1a-a573-8b00d1d99696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   age    age_group  capital_gain  capital_gain_log  capital_loss  capital_net\n",
       " 0   39  Middle-aged          2174          7.684784             0         2174\n",
       " 1   50  Middle-aged             0          0.000000             0            0\n",
       " 2   38  Middle-aged             0          0.000000             0            0\n",
       " 3   53  Middle-aged             0          0.000000             0            0\n",
       " 4   28        Young             0          0.000000             0            0,\n",
       " capital_gain    11.953848\n",
       " capital_loss     4.594629\n",
       " fnlwgt           1.446980\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Copy the dataset to avoid modifying the original\n",
    "df_fe = adult_df.copy()\n",
    "\n",
    "# Create new feature 1: Age Group\n",
    "# Categorize age into bins (Young: <30, Middle-aged: 30â€“60, Senior: >60)\n",
    "df_fe['age_group'] = pd.cut(df_fe['age'], bins=[0, 29, 59, np.inf], labels=['Young', 'Middle-aged', 'Senior'])\n",
    "\n",
    "# Create new feature 2: Capital Net Gain\n",
    "# Difference between capital_gain and capital_loss\n",
    "df_fe['capital_net'] = df_fe['capital_gain'] - df_fe['capital_loss']\n",
    "\n",
    "# Check skewness of numerical columns to identify which one to transform\n",
    "skewed_data = df_fe[['capital_gain', 'capital_loss', 'fnlwgt']].skew()\n",
    "\n",
    "# Apply log transformation to 'capital_gain' due to high skewness (only if > 0)\n",
    "df_fe['capital_gain_log'] = df_fe['capital_gain'].apply(lambda x: np.log1p(x))  # log(1 + x) for zero values\n",
    "\n",
    "# Display the new columns and skewness\n",
    "df_fe[['age', 'age_group', 'capital_gain', 'capital_gain_log', 'capital_loss', 'capital_net']].head(), skewed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdcd5142-c3ef-4ba4-a0c0-d3e8b0de2921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outlier\n",
       " 1    32235\n",
       "-1      326\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Selecting only numerical columns for outlier detection\n",
    "numerical_cols = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "numerical_data = adult_df[numerical_cols]\n",
    "\n",
    "# Applying Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "outliers = iso_forest.fit_predict(numerical_data)\n",
    "\n",
    "# Mark outliers\n",
    "adult_df['Outlier'] = outliers\n",
    "\n",
    "# Count of outliers and non-outliers\n",
    "outlier_counts = adult_df['Outlier'].value_counts()\n",
    "\n",
    "# Remove outliers (where prediction == -1)\n",
    "adult_df_cleaned = adult_df[adult_df['Outlier'] == 1].drop(columns=['Outlier'])\n",
    "\n",
    "outlier_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c7319f8-2b20-4134-b815-d99a02177d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"adult_with_headers.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b8614e-e332-407e-85fb-1e5ee519427c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outlier\n",
       " 1    32235\n",
       "-1      326\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.Outlier Detection with Isolation Forest\n",
    "\n",
    "# 2.Feature Relationship Analysis using PPS and Correlation Matrix\n",
    "\n",
    "\n",
    "#Proceeding with Isolation Forest now\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecting numerical features for Isolation Forest\n",
    "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Apply Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
    "outliers = iso_forest.fit_predict(scaled_data)\n",
    "\n",
    "# Add results to the dataframe\n",
    "df['outlier'] = outliers\n",
    "\n",
    "# Count of outliers detected\n",
    "outlier_counts = df['outlier'].value_counts()\n",
    "\n",
    "# Remove outliers\n",
    "df_cleaned = df[df['outlier'] == 1].drop(columns='outlier')\n",
    "\n",
    "outlier_counts\n",
    "#The Isolation Forest algorithm detected 326 outliers out of 32,561 total entries (~1%). These outliers were removed for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f4e0a01-ad20-4608-8191-2013a1f06bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why Removing Outliers Matters:\n",
    "#Skewed Distributions: Outliers can distort the mean and variance, affecting models like linear regression and clustering.\n",
    "\n",
    "#Overfitting Risk: Models may try to fit these rare points, reducing generalization.\n",
    "\n",
    "#Improved Accuracy: Removal often leads to more robust and reliable models.\n",
    "#1. Impact of Outliers on Model Performance\n",
    "#Outliers are data points that significantly deviate from the norm and can adversely affect machine learning models in several ways:\n",
    "\n",
    "#Skewed Model Parameters: Outliers can disproportionately influence models like linear regression, leading to biased coefficients and poor generalization.\n",
    "#Overfitting: Models may overfit to outliers, especially in tree-based models, reducing performance on typical data.\n",
    "#Increased Variance: Outliers can inflate variance in predictions, making models less stable.\n",
    "#Distorted Metrics: Performance metrics (e.g., RMSE) can be skewed by outliers, misrepresenting model quality.\n",
    "#Feature Importance Errors: Outliers may mislead feature importance rankings in algorithms like random forests.\n",
    "#Removing outliers can improve model robustness, but care must be taken to ensure they are true anomalies and not meaningful rare events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cea9d03d-bd60-4822-b2a1-5ea7c307962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 32561\n",
      "Cleaned dataset size: 29305\n"
     ]
    }
   ],
   "source": [
    "#\"\"\" 2. Outlier Detection with Isolation Forest\n",
    "#Isolation Forest is an unsupervised algorithm that isolates anomalies by randomly selecting features and splitting values. Outliers are identified as points requiring fewer splits to isolate due to their distinctiveness.\n",
    "\n",
    "#Implementation\n",
    "#I'll apply Isolation Forest to the numerical features in the dataset (age, fnlwgt, education_num, capital_gain, capital_loss, hours_per_week). Categorical features will be excluded from outlier detection but retained for later analysis.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('adult_with_headers.csv')\n",
    "\n",
    "# Select numerical features for outlier detection\n",
    "numerical_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "X = data[numerical_features]\n",
    "\n",
    "# Apply Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)  # Assuming 10% outliers\n",
    "outlier_labels = iso_forest.fit_predict(X)\n",
    "\n",
    "# Add outlier labels to the dataset\n",
    "data['outlier'] = outlier_labels\n",
    "\n",
    "# Remove outliers (outlier_label = -1 indicates an outlier)\n",
    "cleaned_data = data[data['outlier'] == 1].drop(columns=['outlier'])\n",
    "print(f\"Original dataset size: {len(data)}\")\n",
    "print(f\"Cleaned dataset size: {len(cleaned_data)}\")\n",
    "\n",
    "#Results\n",
    "#Original dataset size: 32561 (assuming full dataset; sample provided was truncated).\n",
    "#Cleaned dataset size: Approximately 90% of the original size (e.g., ~29305 if 10% are outliers).\n",
    "#Outliers Removed: ~10% of the data, as specified by the contamination parameter.\n",
    "#The Isolation Forest identified outliers based on numerical features. For example, individuals with extreme capital_gain (e.g., 99999) or unusual hours_per_week (e.g., 1 or 99) are likely flagged. The cleaned dataset is now more representative of typical patterns, reducing the risk of model bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf999ad-d682-4b25-b7f0-0039df2d5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Install Required Packages (Jupyter Only) ===\n",
    "%pip install -q ppscore\n",
    "\n",
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import ppscore as pps\n",
    "\n",
    "# === Load Data ===\n",
    "df = pd.read_csv(\"adult_with_headers.csv\")\n",
    "df.columns = df.columns.str.strip()  # Clean column names\n",
    "\n",
    "# === Preview Data ===\n",
    "print(\"Initial shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# === Step 1: Remove Outliers using Isolation Forest (Optimized) ===\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "iso = IsolationForest(\n",
    "    contamination=0.05,\n",
    "    random_state=42,\n",
    "    n_estimators=50,       # Fewer trees to reduce computation\n",
    "    max_samples=1000       # Subsample rows for speed\n",
    ")\n",
    "outliers = iso.fit_predict(df[numeric_cols])\n",
    "df_cleaned = df[outliers == 1]  # Keep only inliers\n",
    "\n",
    "print(\"Shape after outlier removal:\", df_cleaned.shape)\n",
    "\n",
    "# === Step 2: Calculate Predictive Power Score (PPS) ===\n",
    "target = 'income'  # Change this if needed\n",
    "\n",
    "# Sample for PPS to reduce processing time\n",
    "sample_df = df_cleaned.sample(n=min(1000, len(df_cleaned)), random_state=1)\n",
    "pps_matrix = pps.matrix(sample_df)\n",
    "\n",
    "# Filter for target variable\n",
    "pps_scores = pps_matrix[pps_matrix['y'] == target].sort_values(by='ppscore', ascending=False)\n",
    "\n",
    "print(\"\\nTop Predictive Features for Target (PPS):\")\n",
    "display(pps_scores[['x', 'ppscore']])\n",
    "\n",
    "# === Step 3: Correlation Matrix Comparison (Optional) ===\n",
    "if target in numeric_cols:\n",
    "    correlation_scores = df_cleaned[numeric_cols].corr()[target].drop(target).sort_values(ascending=False)\n",
    "\n",
    "    # Merge PPS and Correlation\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Correlation': correlation_scores,\n",
    "        'PPS': pps_scores.set_index('x')['ppscore']\n",
    "    }).dropna()\n",
    "\n",
    "    print(\"\\nComparison of PPS and Correlation with Target:\")\n",
    "    display(comparison_df)\n",
    "\n",
    "    # Plot\n",
    "    comparison_df.sort_values('PPS', ascending=False).plot(kind='bar', figsize=(12, 6))\n",
    "    plt.title('PPS vs Correlation with Target')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"\\nTarget column '{target}' is not numeric, correlation skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3af114-869c-45e9-b9be-a110e7fde0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
