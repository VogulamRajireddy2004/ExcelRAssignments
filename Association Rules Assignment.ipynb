{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620cacd4-24b3-48fa-ad00-219a6696b973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
      "0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
      "1                                            chutney                                                                                                                                                                             \n",
      "2                                     turkey,avocado                                                                                                                                                                             \n",
      "3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
      "4                                     low fat yogurt                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "#  load the dataset Online retail.xlsx\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the file is in your Google Drive, adjust the path if needed\n",
    "df = pd.read_excel('Online retail.xlsx')\n",
    "df\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b94d620-4382-44c0-b47b-182110892268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: No suitable invoice column found. Check the column names in your Excel file.\n"
     ]
    }
   ],
   "source": [
    "#  Data Preprocessing:\n",
    "# Pre-process the dataset to ensure it is suitable for Association rules, this may include handling missing values, removing duplicates, and converting the data to appropriate format.  \n",
    "\n",
    "\n",
    "processed_df = df.copy() \n",
    "\n",
    "# Drop rows with missing values\n",
    "processed_df.dropna(inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "processed_df.drop_duplicates(inplace=True)\n",
    "\n",
    "invoice_column = None  # Initialize a variable to store the invoice column name\n",
    "for col in ['InvoiceNo', 'invoiceno', 'Invoice Number']:\n",
    "    if col in processed_df.columns:\n",
    "        invoice_column = col\n",
    "        break  # Exit the loop if the column is found\n",
    "\n",
    "if invoice_column is not None:\n",
    "    # Rename the column to 'InvoiceNo' if necessary\n",
    "    if invoice_column != 'InvoiceNo':\n",
    "        processed_df.rename(columns={invoice_column: 'InvoiceNo'}, inplace=True)\n",
    "        print(f\"Column name '{invoice_column}' found and renamed to 'InvoiceNo'\")\n",
    "    \n",
    "    # Convert the 'InvoiceNo' column to string type\n",
    "    processed_df['InvoiceNo'] = processed_df['InvoiceNo'].astype(str)\n",
    "\n",
    "    # Remove transactions with cancelled invoices\n",
    "    processed_df = processed_df[~processed_df['InvoiceNo'].str.contains('C')]\n",
    "else:\n",
    "    print(\"Error: No suitable invoice column found. Check the column names in your Excel file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4232d597-edfe-498e-b125-2a93ed37f46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
      "0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
      "1                                            chutney                                                                                                                                                                             \n",
      "2                                     turkey,avocado                                                                                                                                                                             \n",
      "3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
      "4                                     low fat yogurt                                                                                                                                                                             \n",
      "Warning: 'Country' column not found. Skipping missing value removal for this column.\n",
      "Error: No suitable invoice column found. Check the column names in your Excel file.\n"
     ]
    }
   ],
   "source": [
    "#  load the dataset Online retail.xlsx\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming the file is in your Google Drive, adjust the path if needed\n",
    "df = pd.read_excel('Online retail.xlsx')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# prompt: Data Preprocessing:\n",
    "# Pre-process the dataset to ensure it is suitable for Association rules, this may include handling missing values, removing duplicates, and converting the data to appropriate format.  \n",
    "\n",
    "# Make a copy of the original DataFrame to avoid modifying it directly\n",
    "processed_df = df.copy() \n",
    "\n",
    "# Check if 'Country' column exists, if not, skip dropping NA\n",
    "if 'Country' in processed_df.columns:\n",
    "    # Drop rows with missing values in 'Country' column\n",
    "    processed_df.dropna(subset=['Country'], inplace=True)\n",
    "else:\n",
    "    print(\"Warning: 'Country' column not found. Skipping missing value removal for this column.\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "processed_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert the InvoiceNo to string type\n",
    "# Check if 'InvoiceNo' exists in the columns, if not, try variations\n",
    "invoice_column = None  # Initialize a variable to store the invoice column name\n",
    "for col in ['InvoiceNo', 'invoiceno', 'Invoice Number']:\n",
    "    if col in processed_df.columns:\n",
    "        invoice_column = col\n",
    "        break  # Exit the loop if the column is found\n",
    "\n",
    "if invoice_column is not None:\n",
    "    # Rename the column to 'InvoiceNo' if necessary\n",
    "    if invoice_column != 'InvoiceNo':\n",
    "        processed_df.rename(columns={invoice_column: 'InvoiceNo'}, inplace=True)\n",
    "        print(f\"Column name '{invoice_column}' found and renamed to 'InvoiceNo'\")\n",
    "    \n",
    "    # Convert the 'InvoiceNo' column to string type\n",
    "    processed_df['InvoiceNo'] = processed_df['InvoiceNo'].astype(str)\n",
    "\n",
    "    # Remove transactions with cancelled invoices\n",
    "    processed_df = processed_df[~processed_df['InvoiceNo'].str.contains('C')]\n",
    "else:\n",
    "    print(\"Error: No suitable invoice column found. Check the column names in your Excel file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2503e16-c725-47f6-8f67-16d78b9b4a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\users\\vogul\\anaconda4\\lib\\site-packages (0.23.4)Error: 'InvoiceNo' column not found in processed_df. Please check your preprocessing steps.\n",
      "\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from mlxtend) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from mlxtend) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from mlxtend) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.3.1 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from mlxtend) (1.5.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from mlxtend) (3.9.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from scikit-learn>=1.3.1->mlxtend) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vogul\\anaconda4\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#  Analysis and Interpretation:\n",
    "# •\tAnalyse the generated rules to identify interesting patterns and relationships between the products.\n",
    "# •\tInterpret the results and provide insights into customer purchasing behaviour based on the discovered rules.\n",
    "\n",
    "# Import necessary libraries for association rule mining\n",
    "!pip install mlxtend\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Assuming processed_df is your preprocessed DataFrame\n",
    "# Create a one-hot encoded DataFrame for association rule mining\n",
    "\n",
    "# Check if 'InvoiceNo' column exists in processed_df\n",
    "if 'InvoiceNo' in processed_df.columns:\n",
    "    basket = processed_df.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\n",
    "    basket[basket > 0] = 1  # Convert quantities to 1 for presence/absence\n",
    "\n",
    "    # Generate frequent itemsets using apriori\n",
    "    frequent_itemsets = apriori(basket, min_support=0.01, use_colnames=True)\n",
    "\n",
    "    # Generate association rules\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Error: 'InvoiceNo' column not found in processed_df. Please check your preprocessing steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a853ab9-eb44-422f-a7be-80fca18b5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interview Questions:\n",
    "# 1.\tWhat is lift and why is it important in Association rules?\n",
    "# 2.\tWhat is support and Confidence. How do you calculate them?\n",
    "# 3.\tWhat are some limitations or challenges of Association rules mining?\n",
    "\n",
    "# 1. What is lift and why is it important in Association rules?\n",
    "\n",
    "# Lift measures the ratio of the observed support of a rule to the expected support if the antecedent and consequent were independent.  \n",
    "# Lift > 1 implies that the items are more likely to be bought together than if they were independent. \n",
    "# Lift < 1 implies that the items are less likely to be bought together than if they were independent.\n",
    "# Lift = 1 indicates that the items are independent.\n",
    "#\n",
    "# Importance:  Lift helps to identify the truly interesting rules, filtering out those that might occur simply due to high support for individual items.  A high lift value suggests a strong association between the antecedent and the consequent that is not explainable by chance alone.  It's crucial for focusing on the most impactful relationships.\n",
    "\n",
    "\n",
    "# 2. What is support and Confidence. How do you calculate them?\n",
    "\n",
    "# Support: The support of an itemset (or rule) is the proportion of transactions in the dataset that contain that itemset.\n",
    "#    Calculation:  (Number of transactions containing the itemset) / (Total number of transactions)\n",
    "#\n",
    "# Confidence: The confidence of a rule (X => Y) is the conditional probability that a transaction containing X will also contain Y.\n",
    "#    Calculation: (Support of the itemset X ∪ Y) / (Support of the itemset X)\n",
    "#\n",
    "# Example:\n",
    "# Let's say we have 1000 transactions, and in 100 of those transactions, both item A and item B are present.\n",
    "#\n",
    "# Support(A ∪ B) = 100/1000 = 0.1\n",
    "#\n",
    "# Now, suppose that item A appears in 200 transactions.\n",
    "#\n",
    "# Support(A) = 200/1000 = 0.2\n",
    "#\n",
    "# Then the confidence of the rule A => B is:\n",
    "# Confidence(A => B) = Support(A ∪ B) / Support(A) = 0.1 / 0.2 = 0.5\n",
    "\n",
    "\n",
    "# 3. What are some limitations or challenges of Association rules mining?\n",
    "\n",
    "#  Data sparsity: Large datasets often have sparse itemsets, leading to infrequent item combinations. This results in a vast search space and can be computationally expensive.\n",
    "#\n",
    "#  High dimensionality: Datasets with many items can lead to a very high number of possible rules. This can overwhelm the system with irrelevant rules, increasing computation time and making the results difficult to analyze.\n",
    "#\n",
    "#  Minimum support and confidence thresholds: Setting appropriate thresholds for support and confidence is crucial for identifying meaningful rules. An inappropriate choice of thresholds might result in missing important patterns or discovering noisy and irrelevant relationships.\n",
    "#\n",
    "#  Scalability issues: Association rule mining can be computationally intensive, particularly for large datasets. This limits its scalability and the size of problems it can handle effectively.\n",
    "#\n",
    "#  Handling categorical and numerical data: Association rule mining is typically designed to handle categorical data. Special pre-processing is needed for numerical data before applying the algorithms.  Binning or other techniques need to be applied carefully.\n",
    "#\n",
    "#  Lack of interpretability:  While lift and confidence give information, it's still difficult to directly relate the discovered rules to specific causal relationships.\n",
    "#\n",
    "#  Inherent biases:  The data may contain inherent biases which may influence the identified patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c179d3d-e03e-4916-8bcf-5f773d851a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
